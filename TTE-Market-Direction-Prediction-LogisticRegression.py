# ────────────────────────────────────────────────────────────────  
# 1. IMPORTING LIBRARIES  
# ────────────────────────────────────────────────────────────────  

# Visualization
import matplotlib.pyplot as plt   # Basic visualization tools (line plot, bar plot...)
import seaborn as sn              # For heatmaps

# Financial data
import yfinance as yf             # Market data retrieval (Yahoo Finance)

# Numerical operations
import numpy as np                # Numerical calculations (rolling, log, etc.)
import pandas as pd               # DataFrame manipulations (filtering, cleaning, concatenation...)

# Machine Learning
from sklearn.linear_model import LogisticRegression  # Binary classification model
from sklearn.model_selection import TimeSeriesSplit  # Time-based split to preserve data order
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import roc_auc_score, roc_curve  # Performance metrics for classification

pd.set_option("display.max_columns", None)  # Display all columns of a DataFrame

# ────────────────────────────────────────────────────────────────  
# 2. DOWNLOAD DATA & COMPUTE LOG RETURNS  
# ────────────────────────────────────────────────────────────────  

# Download TotalEnergies stock data (ticker: "TTE") since 2000
data = yf.download("TTE", start="2000-01-01", end="2025-07-16")

# Compute daily logarithmic return (more appropriate for statistical analysis)
data["Log_Return"] = np.log(data["Close"] / data["Close"].shift(1))

# ────────────────────────────────────────────────────────────────  
# 3. ADD CLASSIC TECHNICAL INDICATORS  
# ────────────────────────────────────────────────────────────────  

# Moving averages (short and long periods) on log returns
data["MA10"] = data["Log_Return"].rolling(10).mean()
data["MA50"] = data["Log_Return"].rolling(50).mean()

# Detecting moving average crossovers (bullish signal)
data["MA Crossover"] = np.where(data["MA10"] > data["MA50"], 1, 0)

# Rolling standard deviations (historical volatility)
data["MSTD10"] = data["Log_Return"].rolling(10).std()
data["MSTD50"] = data["Log_Return"].rolling(50).std()

# RSI (Relative Strength Index) calculation over 14 days
avg_profit = data["Log_Return"].clip(lower=0).rolling(14).mean()
avg_loss = data["Log_Return"].clip(upper=0).rolling(14).mean()
RS = avg_profit / (-avg_loss)
RSI = 100 - (100 / (1 + RS))
data["RSI"] = RSI

# Rolling Sharpe Ratio (14 days)
risk_free_rate = 0.0202  # Annualized risk-free rate (e.g., 10-year OAT)
trading_days = 252       # Number of trading days per year
daily_risk_free_rate = risk_free_rate / trading_days

sharpe_ratio = (data["Log_Return"].rolling(14).mean() - daily_risk_free_rate) / data["Log_Return"].rolling(14).std()
data["Sharpe Ratio"] = sharpe_ratio

# ────────────────────────────────────────────────────────────────  
# 3. Machine Learning Phase (binary classification)
# ────────────────────────────────────────────────────────────────  

# Create the target variable ("Target"):
# 1 if the price closes higher than the previous day, else 0
data["Target"] = np.where(data["Close"] > data["Close"].shift(1), 1, 0)

# Data preparation
data.dropna(inplace=True)  # Remove rows with NaNs generated by indicators

# Split features / target
X = data.drop("Target", axis=1)
y = data["Target"]

# Time-based split: preserve chronological order (testing on 70%, training on remaining 30%)
# In quantitative finance, it's crucial to avoid future data leakage into training

dates = X.index   # Keep dates for plotting purposes
X_index_reset = X.reset_index(drop=True)
y_index_reset = y.reset_index(drop=True)

tscv = TimeSeriesSplit(n_splits=5, max_train_size=int(0.7 * len(X)))  # Split with 70% max for training

for train_index, test_index in tscv.split(X_index_reset):
    X_train, X_test = X_index_reset.iloc[train_index], X_index_reset.iloc[test_index]
    y_train, y_test = y_index_reset.iloc[train_index], y_index_reset.iloc[test_index]

# Logistic regression
lr = LogisticRegression()
lr.fit(X_train, y_train)

# Predictions
y_pred_proba = lr.predict_proba(X_test)  # Probability of class 1
y_pred = lr.predict(X_test)              # Predicted class

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])

# Result reporting
print("=========================================================================== ")
print("RESULTS - Training with ALL features (raw, unfiltered)")
print("=========================================================================== ")
print("---------------------------------------------------------------------------")
print("-------------------Here are predictions and probabilities ----------------")
print(pd.DataFrame({
    "Predictions": y_pred[0:10].flatten(),
    "Proba 0": y_pred_proba[:10, 0],
    "Proba 1": y_pred_proba[:10, 1]
}))
print("---------------------------------------------------------------------------")
print("-----------------------ROC/AUC Score--------------------------")
print(roc_auc_score(y_test, y_pred_proba[:, 1]))
print("-----------------------Confusion matrix------------------------------")
print(confusion_matrix(y_test, y_pred))
print("-----------------------Classification report--------------------------")
print(classification_report(y_test, y_pred))

# Visualization

plt.figure(figsize=(12, 5))

# Plot 1: ROC Curve
plt.subplot(1, 2, 1)
plt.plot([0, 1], [0, 1], color="skyblue", linestyle='--', label='Random baseline')
plt.plot(fpr, tpr, color="green", label="Logistic Model")
plt.title("ROC Curve (Raw Features) - Model Performance (ROC/AUC Score={})".format(round(roc_auc_score(y_test, y_pred_proba[:, 1]),4)))
plt.xlabel("False Positive Rate (FPR)")
plt.ylabel("True Positive Rate (TPR)")
plt.legend(loc='lower right')

# Plot 2: Confusion matrix
plt.subplot(1, 2, 2)
sn.heatmap(confusion_matrix(y_test, y_pred), cmap="Blues", annot=True, fmt="d")
plt.title("Confusion Matrix - Raw Features")
plt.xlabel("Predictions")
plt.ylabel("True Values")

plt.tight_layout()
plt.show()

# Logistic regression model coefficients
plt.figure(figsize=(10, 5))
plt.bar([str(col) for col in X.columns], lr.coef_.flatten(), color='orange')
plt.xticks(rotation=45, ha="right")
plt.title("Feature Importance - Logistic Regression - Raw Features")
plt.xlabel("Features")
plt.ylabel("Coefficient Weight")
plt.tight_layout()
plt.show()

# Retrain with filtered features (remove low-significance features due to weak coefficients)

data.dropna(inplace=True)
X = data.drop(["Target", "Volume", "MA50", "MSTD10"], axis=1)  # Drop irrelevant variables
y = data["Target"]

# Same time series split
dates = X.index
X_index_reset = X.reset_index(drop=True)
y_index_reset = y.reset_index(drop=True)

tscv = TimeSeriesSplit(n_splits=5, max_train_size=int(0.7 * len(X)))
for train_index, test_index in tscv.split(X_index_reset):
    X_train, X_test = X_index_reset.iloc[train_index], X_index_reset.iloc[test_index]
    y_train, y_test = y_index_reset.iloc[train_index], y_index_reset.iloc[test_index]

# Logistic regression on new selected features
lr = LogisticRegression()
lr.fit(X_train, y_train)

y_pred_proba = lr.predict_proba(X_test)
y_pred = lr.predict(X_test)

fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])

# Result reporting
print("=========================================================================== ")
print("RESULTS - Training with **filtered** features (after cleaning)")
print("=========================================================================== ")

print("---------------------------------------------------------------------------")
print("-------------------Here are predictions and probabilities ----------------")
print(pd.DataFrame({
    "Predictions": y_pred[0:10].flatten(),
    "Proba 0": y_pred_proba[:10, 0],
    "Proba 1": y_pred_proba[:10, 1]
}))
print("---------------------------------------------------------------------------")
print("-----------------------ROC/AUC Score--------------------------")
print(roc_auc_score(y_test, y_pred_proba[:, 1]))
print("-----------------------Confusion matrix------------------------------")
print(confusion_matrix(y_test, y_pred))
print("-----------------------Classification report--------------------------")
print(classification_report(y_test, y_pred))

# Visualization

plt.figure(figsize=(12, 5))

# Plot 1: ROC Curve
plt.subplot(1, 2, 1)
plt.plot([0, 1], [0, 1], color="skyblue", linestyle='--', label='Random baseline')
plt.plot(fpr, tpr, color="green", label="Logistic Model")
plt.title("ROC Curve (Filtered Features) - Model Performance (ROC/AUC Score={})".format(round(roc_auc_score(y_test, y_pred_proba[:, 1]),4)))
plt.xlabel("False Positive Rate (FPR)")
plt.ylabel("True Positive Rate (TPR)")
plt.legend(loc='lower right')

# Plot 2: Confusion matrix
plt.subplot(1, 2, 2)
sn.heatmap(confusion_matrix(y_test, y_pred), cmap="Blues", annot=True, fmt="d")
plt.title("Confusion Matrix - Filtered Features")
plt.xlabel("Predictions")
plt.ylabel("True Values")

plt.tight_layout()
plt.show()

# Logistic regression model coefficients
plt.figure(figsize=(10, 5))
plt.bar([str(col) for col in X.columns], lr.coef_.flatten(), color='orange')
plt.xticks(rotation=45, ha="right")
plt.title("Feature Importance - Logistic Regression - Filtered Features")
plt.xlabel("Features")
plt.ylabel("Coefficient Weight")
plt.tight_layout()
plt.show()

# Trading strategy based on filtered predictions

df_strategy = pd.DataFrame({
    "Predictions": y_pred,
    "Proba (1)": y_pred_proba[:, 1],
    "Open": data["Open"].iloc[test_index].values.flatten(),
    "Close": data["Close"].iloc[test_index].values.flatten()
}, index=data.index[test_index])

df_strategy["Signal"] = np.where((df_strategy["Predictions"] == 1) & (df_strategy["Proba (1)"] >= 0.75), 1, 0)
df_strategy["Position"] = df_strategy["Signal"].shift(1)
df_strategy["Return"] = df_strategy["Close"] / df_strategy["Open"] - 1
df_strategy["Strategy"] = df_strategy["Position"] * df_strategy["Return"]
df_strategy["Cumulative_return"] = ((1 + df_strategy["Strategy"]).cumprod())

# Results 
performance = ((df_strategy.iloc[-1,-1]-1)/1)* 100
highest_performance = df_strategy["Cumulative_return"].max()
lowest_performance = df_strategy["Cumulative_return"].min()
perf_max = ((highest_performance-1)/1)*100
perf_min = ((lowest_performance-1)/1)*100
highest_return = df_strategy["Strategy"].max()
lowest_return = df_strategy["Strategy"].min()

print("----------------------- Trading Strategy Results --------------------------")
print("Overall performance (cumulative):", round(performance, 2), "%")
print("Initial capital value (Cumulative Return):", 1.0)
print("Final capital value (Cumulative Return):", round(df_strategy["Cumulative_return"].iloc[-1], 4))
print("Number of executed trades:", df_strategy["Signal"].sum())
print("Maximum capital value (Cumulative Return):", round(highest_performance, 4))
print("Maximum performance:", round(perf_max, 4), "%")
print("Minimum capital value (Cumulative Return):", round(lowest_performance, 4))
print("Minimum performance:", round(perf_min, 4), "%")
print("Maximum daily return:", round(highest_return * 100, 2), "%")
print("Minimum daily return:", round(lowest_return * 100, 2), "%")
print("Here is the raw result DataFrame:")
print(df_strategy.iloc[:, 5:].dropna())

# Visualize strategy performance
plt.figure
plt.plot(df_strategy.index, df_strategy["Cumulative_return"])
plt.axhline(highest_performance, color="green", linestyle="--", label="Max performance")
plt.axvline(df_strategy["Cumulative_return"].idxmax(),color="green", linestyle="--")
plt.axhline(lowest_performance,color="red", linestyle="--", label="Min performance")
plt.axvline(df_strategy["Cumulative_return"].idxmin(),color="red", linestyle="--")
plt.xticks(rotation=45)
plt.yticks(rotation=45)
plt.title("Trading Strategy Evolution")
plt.xlabel("Date")
plt.ylabel("Cumulative Return")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
